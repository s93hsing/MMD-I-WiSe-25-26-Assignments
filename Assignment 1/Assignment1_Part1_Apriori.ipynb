{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3523ac48",
      "metadata": {},
      "source": [
        "# Mining Media Data I - Assignment 01\n",
        "## Winter Semester 25/26\n",
        "\n",
        "**Prof. Dr. Rafet Sifa | Armin Berger | Dr. Lorenz Sparrenberg**\n",
        "\n",
        "---\n",
        "\n",
        "### Introduction\n",
        "\n",
        "In this assignment, we will investigate methods to mine frequent itemsets, implement the Apriori and the rule extraction algorithms, and apply them to analyze patterns in transactional data. All programming assignments are implemented using Python 3.10+.\n",
        "\n",
        "---\n",
        "\n",
        "## Part 1: Implementation of the Apriori and the Rule Extractor Algorithms (8 Pts.)\n",
        "\n",
        "In this part, using Python, we will implement:\n",
        "1. The **Apriori algorithm** to extract frequent itemsets\n",
        "2. The **rule extraction algorithm** to extract association rules from frequent itemsets\n",
        "\n",
        "We will test the algorithms on the dataset from Table 1 by:\n",
        "- Extracting frequent itemsets for **Smin = 0.1**\n",
        "- Extracting association rules for **Cmin = 0.3**\n",
        "- Calculating the **Lift value** for each rule\n",
        "- Visualizing results using scatter plots with Support, Confidence, and Lift values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eee3ea24",
      "metadata": {},
      "source": [
        "### 1.1 Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "96f5e694",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Matplotlib is building the font cache; this may take a moment.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import combinations\n",
        "from collections import defaultdict\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aed991f5",
      "metadata": {},
      "source": [
        "### 1.2 Transactional Database - Table 1\n",
        "\n",
        "**Table 1:** A transactional DB T for Part 1\n",
        "\n",
        "The dataset contains 8 players with their purchased items:\n",
        "- **Items:** Elixir, Shield, Gem, Sword, Wand, Giant Wand"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ac73b26e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transactional Database:\n",
            "  Player ID                 Bought Items\n",
            "0  Player 1               Elixir, Shield\n",
            "1  Player 2                  Gem, Shield\n",
            "2  Player 3                Elixir, Sword\n",
            "3  Player 4         Elixir, Wand, Shield\n",
            "4  Player 5                Elixir, Sword\n",
            "5  Player 6                 Wand, Shield\n",
            "6  Player 7  Elixir, Wand, Shield, Sword\n",
            "7  Player 8           Elixir, Giant Wand\n",
            "\n",
            "Total transactions: 8\n"
          ]
        }
      ],
      "source": [
        "# Create the transactional database from Table 1\n",
        "transactions = [\n",
        "    ['Elixir', 'Shield'],                      # Player 1\n",
        "    ['Gem', 'Shield'],                         # Player 2\n",
        "    ['Elixir', 'Sword'],                       # Player 3\n",
        "    ['Elixir', 'Wand', 'Shield'],             # Player 4\n",
        "    ['Elixir', 'Sword'],                       # Player 5\n",
        "    ['Wand', 'Shield'],                        # Player 6\n",
        "    ['Elixir', 'Wand', 'Shield', 'Sword'],    # Player 7\n",
        "    ['Elixir', 'Giant Wand']                   # Player 8\n",
        "]\n",
        "\n",
        "# Convert to DataFrame for better visualization\n",
        "df = pd.DataFrame({\n",
        "    'Player ID': [f'Player {i+1}' for i in range(len(transactions))],\n",
        "    'Bought Items': [', '.join(t) for t in transactions]\n",
        "})\n",
        "\n",
        "print(\"Transactional Database:\")\n",
        "print(df)\n",
        "print(f\"\\nTotal transactions: {len(transactions)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ccc15f8",
      "metadata": {},
      "source": [
        "### 1.3 Implementation of the Apriori Algorithm\n",
        "\n",
        "The Apriori algorithm finds frequent itemsets using the principle that:\n",
        "> **All subsets of a frequent itemset must also be frequent.**\n",
        "\n",
        "The algorithm works in passes:\n",
        "1. **Pass 1:** Count 1-itemsets and determine which are frequent\n",
        "2. **Pass k:** Generate candidate k-itemsets from frequent (k-1)-itemsets, then count and prune\n",
        "3. Continue until no new frequent itemsets are found"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1ac42d96",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Apriori algorithm implemented successfully!\n"
          ]
        }
      ],
      "source": [
        "def calculate_support(itemset, transactions):\n",
        "    \"\"\"Calculate support for an itemset\"\"\"\n",
        "    count = sum(1 for transaction in transactions if set(itemset).issubset(set(transaction)))\n",
        "    return count / len(transactions)\n",
        "\n",
        "def get_frequent_1_itemsets(transactions, min_support):\n",
        "    \"\"\"Get frequent 1-itemsets\"\"\"\n",
        "    # Count occurrences of each item\n",
        "    item_counts = defaultdict(int)\n",
        "    for transaction in transactions:\n",
        "        for item in transaction:\n",
        "            item_counts[item] += 1\n",
        "    \n",
        "    # Filter by minimum support\n",
        "    num_transactions = len(transactions)\n",
        "    frequent_items = {}\n",
        "    for item, count in item_counts.items():\n",
        "        support = count / num_transactions\n",
        "        if support >= min_support:\n",
        "            frequent_items[frozenset([item])] = support\n",
        "    \n",
        "    return frequent_items\n",
        "\n",
        "def apriori_gen(frequent_itemsets_prev, k):\n",
        "    \"\"\"Generate candidate k-itemsets from (k-1)-itemsets\"\"\"\n",
        "    candidates = set()\n",
        "    itemsets = list(frequent_itemsets_prev.keys())\n",
        "    \n",
        "    for i in range(len(itemsets)):\n",
        "        for j in range(i + 1, len(itemsets)):\n",
        "            # Join step: merge itemsets that differ by one item\n",
        "            union = itemsets[i] | itemsets[j]\n",
        "            if len(union) == k:\n",
        "                candidates.add(union)\n",
        "    \n",
        "    return candidates\n",
        "\n",
        "def apriori(transactions, min_support):\n",
        "    \"\"\"\n",
        "    Apriori algorithm to find all frequent itemsets\n",
        "    \n",
        "    Parameters:\n",
        "    - transactions: list of transactions (each transaction is a list of items)\n",
        "    - min_support: minimum support threshold\n",
        "    \n",
        "    Returns:\n",
        "    - Dictionary of frequent itemsets with their support values\n",
        "    \"\"\"\n",
        "    # Get frequent 1-itemsets\n",
        "    frequent_itemsets = get_frequent_1_itemsets(transactions, min_support)\n",
        "    all_frequent_itemsets = frequent_itemsets.copy()\n",
        "    \n",
        "    k = 2\n",
        "    while frequent_itemsets:\n",
        "        # Generate candidates\n",
        "        candidates = apriori_gen(frequent_itemsets, k)\n",
        "        \n",
        "        # Prune candidates and calculate support\n",
        "        frequent_itemsets = {}\n",
        "        for candidate in candidates:\n",
        "            support = calculate_support(candidate, transactions)\n",
        "            if support >= min_support:\n",
        "                frequent_itemsets[candidate] = support\n",
        "        \n",
        "        # Add to all frequent itemsets\n",
        "        all_frequent_itemsets.update(frequent_itemsets)\n",
        "        k += 1\n",
        "    \n",
        "    return all_frequent_itemsets\n",
        "\n",
        "print(\"Apriori algorithm implemented successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b39a216d",
      "metadata": {},
      "source": [
        "### 1.4 Extract Frequent Itemsets with Smin = 0.1\n",
        "\n",
        "We now apply the Apriori algorithm to extract all frequent itemsets from Table 1 with a minimum support threshold of **Smin = 0.1**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "cdca22c5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Frequent Itemsets (min_support = 0.1):\n",
            "============================================================\n",
            "\n",
            "1-Itemsets:\n",
            "------------------------------------------------------------\n",
            "  {Elixir} : support = 0.750\n",
            "  {Shield} : support = 0.625\n",
            "  {Sword} : support = 0.375\n",
            "  {Wand} : support = 0.375\n",
            "  {Gem} : support = 0.125\n",
            "  {Giant Wand} : support = 0.125\n",
            "\n",
            "2-Itemsets:\n",
            "------------------------------------------------------------\n",
            "  {Elixir, Sword} : support = 0.375\n",
            "  {Shield, Wand} : support = 0.375\n",
            "  {Elixir, Shield} : support = 0.375\n",
            "  {Elixir, Wand} : support = 0.250\n",
            "  {Shield, Sword} : support = 0.125\n",
            "  {Elixir, Giant Wand} : support = 0.125\n",
            "  {Sword, Wand} : support = 0.125\n",
            "  {Gem, Shield} : support = 0.125\n",
            "\n",
            "3-Itemsets:\n",
            "------------------------------------------------------------\n",
            "  {Elixir, Shield, Wand} : support = 0.250\n",
            "  {Elixir, Shield, Sword} : support = 0.125\n",
            "  {Shield, Sword, Wand} : support = 0.125\n",
            "  {Elixir, Sword, Wand} : support = 0.125\n",
            "\n",
            "4-Itemsets:\n",
            "------------------------------------------------------------\n",
            "  {Elixir, Shield, Sword, Wand} : support = 0.125\n",
            "\n",
            "Total frequent itemsets found: 19\n"
          ]
        }
      ],
      "source": [
        "# Set minimum support\n",
        "min_support = 0.1\n",
        "\n",
        "# Run Apriori algorithm\n",
        "frequent_itemsets = apriori(transactions, min_support)\n",
        "\n",
        "# Display results organized by itemset size\n",
        "print(f\"Frequent Itemsets (min_support = {min_support}):\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Group by itemset size\n",
        "itemsets_by_size = defaultdict(list)\n",
        "for itemset, support in frequent_itemsets.items():\n",
        "    itemsets_by_size[len(itemset)].append((itemset, support))\n",
        "\n",
        "# Display sorted by size and support\n",
        "for size in sorted(itemsets_by_size.keys()):\n",
        "    print(f\"\\n{size}-Itemsets:\")\n",
        "    print(\"-\" * 60)\n",
        "    # Sort by support (descending)\n",
        "    sorted_itemsets = sorted(itemsets_by_size[size], key=lambda x: x[1], reverse=True)\n",
        "    for itemset, support in sorted_itemsets:\n",
        "        items = ', '.join(sorted(itemset))\n",
        "        print(f\"  {{{items}}} : support = {support:.3f}\")\n",
        "\n",
        "print(f\"\\nTotal frequent itemsets found: {len(frequent_itemsets)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c633fce",
      "metadata": {},
      "source": [
        "### 1.5 Implementation of the Rule Extraction Algorithm\n",
        "\n",
        "From the frequent itemsets, we extract association rules and calculate:\n",
        "- **Support:** Frequency of the itemset (A \u222a B)\n",
        "- **Confidence:** Conditional probability P(B|A) = Support(A \u222a B) / Support(A)\n",
        "- **Lift:** Lift(A \u2192 B) = Confidence(A \u2192 B) / Support(B)\n",
        "\n",
        "A lift value > 1 indicates a positive correlation between items."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6f6b20d9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Association rule extraction algorithm implemented successfully!\n"
          ]
        }
      ],
      "source": [
        "def generate_association_rules(frequent_itemsets, min_confidence):\n",
        "    \"\"\"\n",
        "    Generate association rules from frequent itemsets\n",
        "    \n",
        "    Parameters:\n",
        "    - frequent_itemsets: dictionary of frequent itemsets with their support\n",
        "    - min_confidence: minimum confidence threshold\n",
        "    \n",
        "    Returns:\n",
        "    - List of rules with their metrics (support, confidence, lift)\n",
        "    \"\"\"\n",
        "    rules = []\n",
        "    \n",
        "    # Only consider itemsets with 2 or more items\n",
        "    for itemset, support_itemset in frequent_itemsets.items():\n",
        "        if len(itemset) < 2:\n",
        "            continue\n",
        "        \n",
        "        # Generate all possible rules from this itemset\n",
        "        for i in range(1, len(itemset)):\n",
        "            # Generate all combinations of size i as antecedent\n",
        "            for antecedent in combinations(itemset, i):\n",
        "                antecedent = frozenset(antecedent)\n",
        "                consequent = itemset - antecedent\n",
        "                \n",
        "                # Calculate confidence: support(A \u222a B) / support(A)\n",
        "                support_antecedent = frequent_itemsets.get(antecedent, 0)\n",
        "                if support_antecedent == 0:\n",
        "                    continue\n",
        "                \n",
        "                confidence = support_itemset / support_antecedent\n",
        "                \n",
        "                # Check minimum confidence\n",
        "                if confidence >= min_confidence:\n",
        "                    # Calculate lift: confidence / support(B)\n",
        "                    support_consequent = frequent_itemsets.get(consequent, 0)\n",
        "                    if support_consequent > 0:\n",
        "                        lift = confidence / support_consequent\n",
        "                    else:\n",
        "                        lift = 0\n",
        "                    \n",
        "                    rules.append({\n",
        "                        'antecedent': antecedent,\n",
        "                        'consequent': consequent,\n",
        "                        'support': support_itemset,\n",
        "                        'confidence': confidence,\n",
        "                        'lift': lift\n",
        "                    })\n",
        "    \n",
        "    return rules\n",
        "\n",
        "print(\"Association rule extraction algorithm implemented successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77f826b6",
      "metadata": {},
      "source": [
        "### 1.6 Extract Association Rules with Cmin = 0.3\n",
        "\n",
        "We now extract association rules from the frequent itemsets with a minimum confidence threshold of **Cmin = 0.3**.\n",
        "\n",
        "For each rule, we calculate and display:\n",
        "- **Support**\n",
        "- **Confidence**\n",
        "- **Lift**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6089e991",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Association Rules (min_confidence = 0.3):\n",
            "================================================================================\n",
            "\n",
            "Rule 1: {Shield, Sword} => {Elixir, Wand}\n",
            "  Support:    0.125\n",
            "  Confidence: 1.000\n",
            "  Lift:       4.000\n",
            "\n",
            "Rule 2: {Shield, Sword} => {Wand}\n",
            "  Support:    0.125\n",
            "  Confidence: 1.000\n",
            "  Lift:       2.667\n",
            "\n",
            "Rule 3: {Sword, Wand} => {Elixir, Shield}\n",
            "  Support:    0.125\n",
            "  Confidence: 1.000\n",
            "  Lift:       2.667\n",
            "\n",
            "Rule 4: {Elixir, Shield, Sword} => {Wand}\n",
            "  Support:    0.125\n",
            "  Confidence: 1.000\n",
            "  Lift:       2.667\n",
            "\n",
            "Rule 5: {Wand} => {Shield}\n",
            "  Support:    0.375\n",
            "  Confidence: 1.000\n",
            "  Lift:       1.600\n",
            "\n",
            "Rule 6: {Gem} => {Shield}\n",
            "  Support:    0.125\n",
            "  Confidence: 1.000\n",
            "  Lift:       1.600\n",
            "\n",
            "Rule 7: {Elixir, Wand} => {Shield}\n",
            "  Support:    0.250\n",
            "  Confidence: 1.000\n",
            "  Lift:       1.600\n",
            "\n",
            "Rule 8: {Sword, Wand} => {Shield}\n",
            "  Support:    0.125\n",
            "  Confidence: 1.000\n",
            "  Lift:       1.600\n",
            "\n",
            "Rule 9: {Elixir, Sword, Wand} => {Shield}\n",
            "  Support:    0.125\n",
            "  Confidence: 1.000\n",
            "  Lift:       1.600\n",
            "\n",
            "Rule 10: {Sword} => {Elixir}\n",
            "  Support:    0.375\n",
            "  Confidence: 1.000\n",
            "  Lift:       1.333\n",
            "\n",
            "Rule 11: {Giant Wand} => {Elixir}\n",
            "  Support:    0.125\n",
            "  Confidence: 1.000\n",
            "  Lift:       1.333\n",
            "\n",
            "Rule 12: {Shield, Sword} => {Elixir}\n",
            "  Support:    0.125\n",
            "  Confidence: 1.000\n",
            "  Lift:       1.333\n",
            "\n",
            "Rule 13: {Sword, Wand} => {Elixir}\n",
            "  Support:    0.125\n",
            "  Confidence: 1.000\n",
            "  Lift:       1.333\n",
            "\n",
            "Rule 14: {Shield, Sword, Wand} => {Elixir}\n",
            "  Support:    0.125\n",
            "  Confidence: 1.000\n",
            "  Lift:       1.333\n",
            "\n",
            "Rule 15: {Wand} => {Elixir, Shield}\n",
            "  Support:    0.250\n",
            "  Confidence: 0.667\n",
            "  Lift:       1.778\n",
            "\n",
            "Rule 16: {Elixir, Shield} => {Wand}\n",
            "  Support:    0.250\n",
            "  Confidence: 0.667\n",
            "  Lift:       1.778\n",
            "\n",
            "Rule 17: {Wand} => {Elixir}\n",
            "  Support:    0.250\n",
            "  Confidence: 0.667\n",
            "  Lift:       0.889\n",
            "\n",
            "Rule 18: {Shield, Wand} => {Elixir}\n",
            "  Support:    0.250\n",
            "  Confidence: 0.667\n",
            "  Lift:       0.889\n",
            "\n",
            "Rule 19: {Shield} => {Wand}\n",
            "  Support:    0.375\n",
            "  Confidence: 0.600\n",
            "  Lift:       1.600\n",
            "\n",
            "Rule 20: {Shield} => {Elixir}\n",
            "  Support:    0.375\n",
            "  Confidence: 0.600\n",
            "  Lift:       0.800\n",
            "\n",
            "Rule 21: {Elixir, Wand} => {Shield, Sword}\n",
            "  Support:    0.125\n",
            "  Confidence: 0.500\n",
            "  Lift:       4.000\n",
            "\n",
            "Rule 22: {Elixir} => {Sword}\n",
            "  Support:    0.375\n",
            "  Confidence: 0.500\n",
            "  Lift:       1.333\n",
            "\n",
            "Rule 23: {Elixir, Wand} => {Sword}\n",
            "  Support:    0.125\n",
            "  Confidence: 0.500\n",
            "  Lift:       1.333\n",
            "\n",
            "Rule 24: {Elixir, Shield, Wand} => {Sword}\n",
            "  Support:    0.125\n",
            "  Confidence: 0.500\n",
            "  Lift:       1.333\n",
            "\n",
            "Rule 25: {Elixir} => {Shield}\n",
            "  Support:    0.375\n",
            "  Confidence: 0.500\n",
            "  Lift:       0.800\n",
            "\n",
            "Rule 26: {Shield} => {Elixir, Wand}\n",
            "  Support:    0.250\n",
            "  Confidence: 0.400\n",
            "  Lift:       1.600\n",
            "\n",
            "Rule 27: {Wand} => {Shield, Sword}\n",
            "  Support:    0.125\n",
            "  Confidence: 0.333\n",
            "  Lift:       2.667\n",
            "\n",
            "Rule 28: {Wand} => {Elixir, Shield, Sword}\n",
            "  Support:    0.125\n",
            "  Confidence: 0.333\n",
            "  Lift:       2.667\n",
            "\n",
            "Rule 29: {Elixir, Shield} => {Sword, Wand}\n",
            "  Support:    0.125\n",
            "  Confidence: 0.333\n",
            "  Lift:       2.667\n",
            "\n",
            "Rule 30: {Sword} => {Elixir, Wand}\n",
            "  Support:    0.125\n",
            "  Confidence: 0.333\n",
            "  Lift:       1.333\n",
            "\n",
            "Rule 31: {Sword} => {Elixir, Shield, Wand}\n",
            "  Support:    0.125\n",
            "  Confidence: 0.333\n",
            "  Lift:       1.333\n",
            "\n",
            "Rule 32: {Elixir} => {Wand}\n",
            "  Support:    0.250\n",
            "  Confidence: 0.333\n",
            "  Lift:       0.889\n",
            "\n",
            "Rule 33: {Wand} => {Sword}\n",
            "  Support:    0.125\n",
            "  Confidence: 0.333\n",
            "  Lift:       0.889\n",
            "\n",
            "Rule 34: {Sword} => {Wand}\n",
            "  Support:    0.125\n",
            "  Confidence: 0.333\n",
            "  Lift:       0.889\n",
            "\n",
            "Rule 35: {Elixir} => {Shield, Wand}\n",
            "  Support:    0.250\n",
            "  Confidence: 0.333\n",
            "  Lift:       0.889\n",
            "\n",
            "Rule 36: {Sword} => {Elixir, Shield}\n",
            "  Support:    0.125\n",
            "  Confidence: 0.333\n",
            "  Lift:       0.889\n",
            "\n",
            "Rule 37: {Elixir, Shield} => {Sword}\n",
            "  Support:    0.125\n",
            "  Confidence: 0.333\n",
            "  Lift:       0.889\n",
            "\n",
            "Rule 38: {Sword} => {Shield, Wand}\n",
            "  Support:    0.125\n",
            "  Confidence: 0.333\n",
            "  Lift:       0.889\n",
            "\n",
            "Rule 39: {Shield, Wand} => {Sword}\n",
            "  Support:    0.125\n",
            "  Confidence: 0.333\n",
            "  Lift:       0.889\n",
            "\n",
            "Rule 40: {Wand} => {Elixir, Sword}\n",
            "  Support:    0.125\n",
            "  Confidence: 0.333\n",
            "  Lift:       0.889\n",
            "\n",
            "Rule 41: {Elixir, Sword} => {Wand}\n",
            "  Support:    0.125\n",
            "  Confidence: 0.333\n",
            "  Lift:       0.889\n",
            "\n",
            "Rule 42: {Shield, Wand} => {Elixir, Sword}\n",
            "  Support:    0.125\n",
            "  Confidence: 0.333\n",
            "  Lift:       0.889\n",
            "\n",
            "Rule 43: {Elixir, Sword} => {Shield, Wand}\n",
            "  Support:    0.125\n",
            "  Confidence: 0.333\n",
            "  Lift:       0.889\n",
            "\n",
            "Rule 44: {Sword} => {Shield}\n",
            "  Support:    0.125\n",
            "  Confidence: 0.333\n",
            "  Lift:       0.533\n",
            "\n",
            "Rule 45: {Elixir, Sword} => {Shield}\n",
            "  Support:    0.125\n",
            "  Confidence: 0.333\n",
            "  Lift:       0.533\n",
            "\n",
            "================================================================================\n",
            "Total rules found: 45\n"
          ]
        }
      ],
      "source": [
        "# Set minimum confidence\n",
        "min_confidence = 0.3\n",
        "\n",
        "# Generate association rules\n",
        "rules = generate_association_rules(frequent_itemsets, min_confidence)\n",
        "\n",
        "# Display rules\n",
        "print(f\"Association Rules (min_confidence = {min_confidence}):\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Sort rules by confidence (descending)\n",
        "rules_sorted = sorted(rules, key=lambda x: (x['confidence'], x['lift']), reverse=True)\n",
        "\n",
        "for i, rule in enumerate(rules_sorted, 1):\n",
        "    antecedent_str = ', '.join(sorted(rule['antecedent']))\n",
        "    consequent_str = ', '.join(sorted(rule['consequent']))\n",
        "    \n",
        "    print(f\"\\nRule {i}: {{{antecedent_str}}} => {{{consequent_str}}}\")\n",
        "    print(f\"  Support:    {rule['support']:.3f}\")\n",
        "    print(f\"  Confidence: {rule['confidence']:.3f}\")\n",
        "    print(f\"  Lift:       {rule['lift']:.3f}\")\n",
        "\n",
        "print(f\"\\n{'=' * 80}\")\n",
        "print(f\"Total rules found: {len(rules)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f856962f",
      "metadata": {},
      "source": [
        "### 1.7 Visualization - Scatter Plot\n",
        "\n",
        "**Visualization requirements:**\n",
        "- X-axis: **Support** values\n",
        "- Y-axis: **Confidence** values\n",
        "- **Lift values** incorporated through:\n",
        "  - **Color intensity:** Higher lift = brighter color\n",
        "  - **Marker size:** Larger markers indicate higher lift\n",
        "\n",
        "This allows us to visualize all three metrics (Support, Confidence, and Lift) in a single plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ca70759",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract metrics for plotting\n",
        "supports = [rule['support'] for rule in rules]\n",
        "confidences = [rule['confidence'] for rule in rules]\n",
        "lifts = [rule['lift'] for rule in rules]\n",
        "\n",
        "# Create scatter plot\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "# Use lift for both color and size\n",
        "scatter = ax.scatter(supports, confidences, \n",
        "                     c=lifts, \n",
        "                     s=[l * 100 for l in lifts],  # Size proportional to lift\n",
        "                     cmap='viridis', \n",
        "                     alpha=0.7,\n",
        "                     edgecolors='black',\n",
        "                     linewidth=1.5)\n",
        "\n",
        "# Add colorbar for lift\n",
        "cbar = plt.colorbar(scatter, ax=ax)\n",
        "cbar.set_label('Lift', rotation=270, labelpad=20, fontsize=12)\n",
        "\n",
        "# Labels and title\n",
        "ax.set_xlabel('Support', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('Confidence', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Association Rules: Support vs Confidence (colored and sized by Lift)', \n",
        "             fontsize=14, fontweight='bold', pad=20)\n",
        "\n",
        "# Add grid\n",
        "ax.grid(True, alpha=0.3, linestyle='--')\n",
        "\n",
        "# Add reference lines\n",
        "ax.axhline(y=min_confidence, color='r', linestyle='--', alpha=0.5, label=f'Min Confidence = {min_confidence}')\n",
        "ax.axvline(x=min_support, color='b', linestyle='--', alpha=0.5, label=f'Min Support = {min_support}')\n",
        "\n",
        "# Annotate some key rules\n",
        "for i, rule in enumerate(rules_sorted[:5]):  # Top 5 rules\n",
        "    antecedent_str = ', '.join(sorted(rule['antecedent']))\n",
        "    consequent_str = ', '.join(sorted(rule['consequent']))\n",
        "    label = f\"{{{antecedent_str}}} => {{{consequent_str}}}\"\n",
        "    \n",
        "    ax.annotate(label, \n",
        "                xy=(rule['support'], rule['confidence']),\n",
        "                xytext=(10, 10), \n",
        "                textcoords='offset points',\n",
        "                fontsize=8,\n",
        "                bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.5),\n",
        "                arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0', color='black'))\n",
        "\n",
        "ax.legend(loc='lower right', fontsize=10)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\ud83d\udcca Visualization Tips:\")\n",
        "print(\"  - Larger/brighter points indicate higher Lift values\")\n",
        "print(\"  - Points in the upper-right corner have both high support and confidence\")\n",
        "print(\"  - Lift > 1 indicates positive correlation between items\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd9281db",
      "metadata": {},
      "source": [
        "### 1.8 Summary Statistics and Key Insights\n",
        "\n",
        "Analysis of the results from the Apriori algorithm and rule extraction on Table 1 dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86683a94",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create summary statistics\n",
        "print(\"=\" * 80)\n",
        "print(\"SUMMARY STATISTICS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(f\"\\n\ud83d\udcca Dataset Information:\")\n",
        "print(f\"  Total transactions: {len(transactions)}\")\n",
        "print(f\"  Unique items: {len(set(item for trans in transactions for item in trans))}\")\n",
        "print(f\"  Average items per transaction: {np.mean([len(t) for t in transactions]):.2f}\")\n",
        "\n",
        "print(f\"\\n\ud83d\udd0d Frequent Itemsets:\")\n",
        "print(f\"  Total frequent itemsets: {len(frequent_itemsets)}\")\n",
        "for size in sorted(itemsets_by_size.keys()):\n",
        "    print(f\"  {size}-itemsets: {len(itemsets_by_size[size])}\")\n",
        "\n",
        "print(f\"\\n\ud83d\udccf Association Rules:\")\n",
        "print(f\"  Total rules: {len(rules)}\")\n",
        "print(f\"  Average support: {np.mean(supports):.3f}\")\n",
        "print(f\"  Average confidence: {np.mean(confidences):.3f}\")\n",
        "print(f\"  Average lift: {np.mean(lifts):.3f}\")\n",
        "\n",
        "print(f\"\\n\u2b50 Top 5 Rules by Confidence:\")\n",
        "for i, rule in enumerate(rules_sorted[:5], 1):\n",
        "    antecedent_str = ', '.join(sorted(rule['antecedent']))\n",
        "    consequent_str = ', '.join(sorted(rule['consequent']))\n",
        "    print(f\"  {i}. {{{antecedent_str}}} => {{{consequent_str}}}\")\n",
        "    print(f\"     Conf: {rule['confidence']:.3f}, Lift: {rule['lift']:.3f}\")\n",
        "\n",
        "print(\"\\n\ud83d\udca1 Key Insights:\")\n",
        "print(\"  - Elixir is the most frequently purchased item\")\n",
        "print(\"  - Shield appears in many itemsets, suggesting it's popular\")\n",
        "print(\"  - High lift values indicate strong item associations\")\n",
        "print(\"  - Rules with lift > 1 show items bought together more often than expected\")\n",
        "print(\"=\" * 80)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}